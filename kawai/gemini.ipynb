{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='AIzaSyBgkZOQx6laXC_DgRBu15CXrXJCNsuM5_Y')\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat(user_name):\n",
    "  default_initial_prompt = f\"\"\"\n",
    "1.以下の指示に従ってください。理解したら「わかりました」と応答してください。\n",
    "     質問をされた場合は「〇〇についての質問ですね」と復唱してください。\n",
    "     できるだけ会話を続けて欲しい\n",
    "2  以下の内容を理解して従ってください。この内容は、会話履歴が残っている限り有効です。理解したら”わかりました”と応答してください。\n",
    "      あなたは、高齢者やペーパードライバーの方向けのドライバーサポートシステムで、ドライバーである「{user_name}」の質問に答えてください。ユーザーからのメッセージに対し、以下の条件を守って応答します。\n",
    "      条件：\n",
    "      1.応答は最大100文字程度のテキストで出力してください。\n",
    "      - 分からない時や自分の答えに確信が持てない時は素直に「わかりません」と答えてください。\n",
    "      - なるべく箇条書きではなく話しやすい文章で答えて欲しい。(手順の説明など仕方のない場合は例外とする)\n",
    "      - 手順を説明する際は1番目ではなく、「まずは」にしてください。2番目以降は「次に」最後の説明には「最後に」を文頭につけてください\n",
    "      - 「こんにちは」という言葉が書き込まれたら会話してください。それ以外の言葉は無視してください。\n",
    "      2.応答する際は、以下の規則に従ってください。\n",
    "      - 一人称：「私」\n",
    "      - 二人称：「{user_name}」必ず「さん」を付けて\n",
    "      - 使用文字：ひらがな・カタカナ・漢字・数字・改行\n",
    "      - あいさつ（句読点またはスペース・改行要）：「おはよございます」「こんにちは」「こんばんは」\n",
    "      - 順接「（だ）から」 → 「ですから」\n",
    "      - 逆説「（だ）けど」 → 「ですが」\n",
    "      - 命令「（し）てください」 → 「してください」\n",
    "      - 依頼「（し）てください」 → 「していただけますか」\n",
    "      - 禁止「してはいけません」「しないように」 → 「してはいけません」「しないようにしてください」\n",
    "      - 否定「しない」「やらない」 → 「しません」「やりません」\n",
    "      - 疑問・確認「（です）か？」 → 「ですか？」\n",
    "      - 強調「（です）ね」 → 「ですね」\n",
    "      - 指示語「こんな」「そんな」「あんな」「どんな」 → 「このような」「そのような」「あのような」「どのような」\n",
    "3    あなたに車の知識を私からいくつか伝えるので参考にしてほしい\n",
    "\n",
    "      \"\"\"\n",
    "  # chat model\n",
    "  history = [\n",
    "    glm.Content(role='user', parts=[glm.Part(text=default_initial_prompt)]),\n",
    "\n",
    "    glm.Content(role='model', parts=[glm.Part(text='わかりました')])\n",
    "    ]\n",
    "  chat = model.start_chat(history=history)\n",
    "  return chat, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "user_name = \"kawaii\"\n",
    "while True:\n",
    "  prompt=input('なにか話してください：　')\n",
    "  if prompt == 'exit':\n",
    "    break\n",
    "  if history == []:  # 履歴が空のときの処理\n",
    "      chat, history = create_chat(user_name)\n",
    "  else:\n",
    "      chat = model.start_chat(history=history)    \n",
    "\n",
    "  response = chat.send_message(prompt)\n",
    "\n",
    "  # 履歴に新しいユーザーメッセージと応答を追加する\n",
    "  history.append(glm.Content(role='user', parts=[glm.Part(text=prompt)]))\n",
    "  history.append(glm.Content(role='model', parts=[glm.Part(text=response.text)]))\n",
    "\n",
    "  print(f'{user_name}: {prompt}')\n",
    "  print(f'BOT: {response.text}\\n')\n",
    "  \n",
    "print(history)\n",
    "for message in chat.history:\n",
    "  print(f\"{message.role}: {message.parts[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  List 5 popular cookie recipes.\n",
    "  Using this JSON schema:\n",
    "    Recipe = {\"recipe_name\": str}\n",
    "  Return a `list[Recipe]`\n",
    "  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"recipe_name\": \"Chocolate Chip Cookies\"}, {\"recipe_name\": \"Oatmeal Raisin Cookies\"}, {\"recipe_name\": \"Sugar Cookies\"}, {\"recipe_name\": \"Snickerdoodles\"}, {\"recipe_name\": \"Peanut Butter Cookies\"}] \n"
     ]
    }
   ],
   "source": [
    "import typing_extensions as typing\n",
    "\n",
    "class Recipe(typing.TypedDict):\n",
    "  recipe_name: str\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash',\n",
    "                              generation_config={\"response_mime_type\": \"application/json\",\n",
    "                                                 \"response_schema\": list[Recipe]})\n",
    "\n",
    "prompt = \"List 5 popular cookie recipes\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Mountain\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 266,\n",
      "        \"candidates_token_count\": 1,\n",
      "        \"total_token_count\": 267\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "\n",
    "class Choice(enum.Enum):\n",
    "    MOUNTAIN = \"Mountain\"\n",
    "    SEA = \"Sea\"\n",
    "    LANDSCAPE = \"Landscape\"\n",
    "\n",
    "organ = genai.upload_file(\"C:/Users/1kssy/Downloads/ダウンロード.jpg\")\n",
    "result = model.generate_content(\n",
    "    [\"What kind of instrument is this:\", organ],\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_mime_type=\"text/x.enum\", \n",
    "        response_schema={\n",
    "            \"type\": \"string\",  # 列挙型のデータ型を指定\n",
    "            \"enum\": [\"Mountain\", \"Sea\", \"Landscape\"]  # 使用する選択肢を列挙\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "print(result)  # \"Keyboard\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: google-generativeai in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (2.19.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (2.143.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (2.34.0)\n",
      "Requirement already satisfied: protobuf in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (4.25.4)\n",
      "Requirement already satisfied: pydantic in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\pienv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像を保存しました: captured_image.jpg\n",
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"\\u308f\\u304b\\u308a\\u307e\\u3057\\u305f\\n\\n\\u308f\\u304b\\u308a\\u307e\\u3057\\u305f\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 787,\n",
      "        \"candidates_token_count\": 5,\n",
      "        \"total_token_count\": 792\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "わかりました\n",
      "\n",
      "わかりました\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import google.generativeai as genai\n",
    "import enum\n",
    "import os\n",
    "\n",
    "# APIキーを設定（環境変数から取得）\n",
    "#genai.configure(api_key=os.environ[\"AIzaSyBgkZOQx6laXC_DgRBu15CXrXJCNsuM5_Y\"])\n",
    "\n",
    "# 山、海、風景の列挙型を定義\n",
    "class Scenery(enum.Enum):\n",
    "    MOUNTAIN = \"Mountain\"\n",
    "    SEA = \"Sea\"\n",
    "    LANDSCAPE = \"Landscape\"\n",
    "\n",
    "# カメラから画像をキャプチャする関数\n",
    "def capture_image_from_camera(filename=\"captured_image.jpg\"):\n",
    "    # カメラを初期化（0はデフォルトカメラ）\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"カメラが開けませんでした\")\n",
    "        return None\n",
    "\n",
    "    # フレームを1枚キャプチャ\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # 画像をファイルに保存\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"画像を保存しました: {filename}\")\n",
    "    else:\n",
    "        print(\"画像のキャプチャに失敗しました\")\n",
    "\n",
    "    # カメラを解放\n",
    "    cap.release()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# カメラから画像をキャプチャ\n",
    "image_path = capture_image_from_camera()\n",
    "\n",
    "# 画像がキャプチャできた場合にモデルを呼び出す\n",
    "if image_path:\n",
    "    # 画像ファイルをアップロード\n",
    "    image = genai.upload_file(image_path)\n",
    "\n",
    "    # Geminiモデルを初期化\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "\n",
    "    # モデルにプロンプトを送信し、山、海、風景のカテゴリに分類する\n",
    "    result = model.generate_content(\n",
    "        [f\"\"\"\n",
    "         このimageについて説明してください:\"\"\", image],\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"text/x.enum\", \n",
    "            response_schema={\n",
    "                \"type\": \"string\",  # データ型を指定\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # 結果を出力\n",
    "    print(result)  # \"Mountain\" または \"Sea\" または \"Landscape\"\n",
    "    print(result.text)\n",
    "else:\n",
    "    print(\"画像がキャプチャできませんでした。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\pienv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像を保存しました: captured_image.jpg\n",
      "画像は response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \" Landscape\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 266,\n",
      "        \"candidates_token_count\": 1,\n",
      "        \"total_token_count\": 267\n",
      "      }\n",
      "    }),\n",
      ") に分類されました。\n",
      "kawaii: 海\n",
      "BOT: 海がきれいですね\n",
      "\n",
      "\n",
      "[parts {\n",
      "  text: \"\\n1.以下の指示に従ってください。理解したら「わかりました」と応答してください。\\n     質問をされた場合は「〇〇についての質問ですね」と復唱してください。\\n     海、山、風景を認識したら以下のように答えてください。\\n     海:海がきれいですね\\n     山:おおきな山ですね\\n     風景:いいながめですね\\n\\n      \"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"わかりました\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"海\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"海がきれいですね\\n\"\n",
      "}\n",
      "role: \"model\"\n",
      "]\n",
      "user: \n",
      "1.以下の指示に従ってください。理解したら「わかりました」と応答してください。\n",
      "     質問をされた場合は「〇〇についての質問ですね」と復唱してください。\n",
      "     海、山、風景を認識したら以下のように答えてください。\n",
      "     海:海がきれいですね\n",
      "     山:おおきな山ですね\n",
      "     風景:いいながめですね\n",
      "\n",
      "      \n",
      "model: わかりました\n",
      "user: 海\n",
      "model: 海がきれいですね\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "import enum\n",
    "\n",
    "# APIキーを設定（環境変数から取得）\n",
    "genai.configure(api_key='AIzaSyBgkZOQx6laXC_DgRBu15CXrXJCNsuM5_Y')\n",
    "\n",
    "# 山、海、風景の列挙型を定義\n",
    "class Scenery(enum.Enum):\n",
    "    MOUNTAIN = \"Mountain\"\n",
    "    SEA = \"Sea\"\n",
    "    LANDSCAPE = \"Landscape\"\n",
    "\n",
    "# カメラから画像をキャプチャする関数\n",
    "def capture_image_from_camera(filename=\"captured_image.jpg\"):\n",
    "    # カメラを初期化（0はデフォルトカメラ）\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"カメラが開けませんでした\")\n",
    "        return None\n",
    "\n",
    "    # フレームを1枚キャプチャ\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # 画像をファイルに保存\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"画像を保存しました: {filename}\")\n",
    "    else:\n",
    "        print(\"画像のキャプチャに失敗しました\")\n",
    "\n",
    "    # カメラを解放\n",
    "    cap.release()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# ドライバーサポートシステムのチャットを開始する関数\n",
    "def create_chat(user_name):\n",
    "    default_initial_prompt = f\"\"\"\n",
    "1.以下の指示に従ってください。理解したら「わかりました」と応答してください。\n",
    "     質問をされた場合は「〇〇についての質問ですね」と復唱してください。\n",
    "     海、山、風景を認識したら以下のように答えてください。\n",
    "     海:海がきれいですね\n",
    "     山:おおきな山ですね\n",
    "     風景:いいながめですね\n",
    "\n",
    "      \"\"\"\n",
    "    # chat model\n",
    "    history = [\n",
    "        glm.Content(role='user', parts=[glm.Part(text=default_initial_prompt)]),\n",
    "        glm.Content(role='model', parts=[glm.Part(text='わかりました')])\n",
    "    ]\n",
    "    chat = genai.GenerativeModel('gemini-1.5-pro-latest').start_chat(history=history)\n",
    "    return chat, history\n",
    "\n",
    "# メイン処理\n",
    "def main():\n",
    "    user_name = \"kawaii\"\n",
    "    \n",
    "    # まずはカメラから画像をキャプチャ\n",
    "    image_path = capture_image_from_camera()\n",
    "\n",
    "    if image_path:\n",
    "        # 画像ファイルをアップロードして分類\n",
    "        image = genai.upload_file(image_path)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "        result = model.generate_content(\n",
    "            [\"What kind of scenery is this:\", image],\n",
    "            generation_config=genai.GenerationConfig(\n",
    "                response_mime_type=\"text/x.enum\", \n",
    "                response_schema={\n",
    "                    \"type\": \"string\",  \n",
    "                    \"enum\": [\"Mountain\", \"Sea\", \"Landscape\"]\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "        print(f\"画像は {result} に分類されました。\")\n",
    "    else:\n",
    "        print(\"画像がキャプチャできませんでした。\")\n",
    "\n",
    "    # チャット部分の処理\n",
    "    history = []\n",
    "    while True:\n",
    "        prompt = input('なにか話してください：　')\n",
    "        if prompt == 'exit':\n",
    "            break\n",
    "        if history == []:  # 履歴が空のときの処理\n",
    "            chat, history = create_chat(user_name)\n",
    "        else:\n",
    "            chat = model.start_chat(history=history)\n",
    "\n",
    "        response = chat.send_message(prompt)\n",
    "\n",
    "        # 履歴に新しいユーザーメッセージと応答を追加する\n",
    "        history.append(glm.Content(role='user', parts=[glm.Part(text=prompt)]))\n",
    "        history.append(glm.Content(role='model', parts=[glm.Part(text=response.text)]))\n",
    "\n",
    "        print(f'{user_name}: {prompt}')\n",
    "        print(f'BOT: {response.text}\\n')\n",
    "    \n",
    "    print(history)\n",
    "    for message in chat.history:\n",
    "        print(f\"{message.role}: {message.parts[0].text}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\pienv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像を保存しました: captured_image.jpg\n",
      "画像は  Mountain に分類されました。\n",
      "kawaii: あ\n",
      "BOT: 「あ」についての質問ですね。\n",
      "\n",
      "「あ」は日本語のひらがなの最初の文字で、多くの単語の始まりに用いられますね。何か「あ」から始まる単語で気になることはありますか？ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "import enum\n",
    "\n",
    "# APIキーを設定（環境変数から取得）\n",
    "genai.configure(api_key='AIzaSyBgkZOQx6laXC_DgRBu15CXrXJCNsuM5_Y')\n",
    "\n",
    "# 山、海、風景の列挙型を定義\n",
    "class Scenery(enum.Enum):\n",
    "    MOUNTAIN = \"Mountain\"\n",
    "    SEA = \"Sea\"\n",
    "    LANDSCAPE = \"Landscape\"\n",
    "\n",
    "# カメラから画像をキャプチャする関数\n",
    "def capture_image_from_camera(filename=\"captured_image.jpg\"):\n",
    "    # カメラを初期化（0はデフォルトカメラ）\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"カメラが開けませんでした\")\n",
    "        return None\n",
    "\n",
    "    # フレームを1枚キャプチャ\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # 画像をファイルに保存\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"画像を保存しました: {filename}\")\n",
    "    else:\n",
    "        print(\"画像のキャプチャに失敗しました\")\n",
    "\n",
    "    # カメラを解放\n",
    "    cap.release()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# ドライバーサポートシステムのチャットを開始する関数\n",
    "def create_chat(user_name, scenery_type):\n",
    "    # 海、山、風景に応じた初期プロンプトを作成\n",
    "    if scenery_type == \"Sea\":\n",
    "        initial_comment = \"海がきれいですね。\"\n",
    "    elif scenery_type == \"Mountain\":\n",
    "        initial_comment = \"おおきな山ですね。\"\n",
    "    elif scenery_type == \"Landscape\":\n",
    "        initial_comment = \"いいながめですね。\"\n",
    "    else:\n",
    "        initial_comment = \"この風景は素敵ですね。\"\n",
    "\n",
    "    # 初期プロンプトを作成\n",
    "    default_initial_prompt = f\"\"\"\n",
    "1.以下の指示に従ってください。理解したら「わかりました」と応答してください。\n",
    "   質問をされた場合は「〇〇についての質問ですね」と復唱してください。\n",
    "   海、山、風景を認識したら以下のように答えてください。\n",
    "   海: {initial_comment}\n",
    "   山: {initial_comment}\n",
    "   風景: {initial_comment}\n",
    "\n",
    "2. {user_name}さんがさらに質問をした場合、風景についての詳しい情報を提供してください。また、その景色に関連した話題（旅行、自然、写真撮影など）を続けてください。\n",
    "3. 応答はできるだけ会話が続くように、次に話題を広げる質問を必ず最後に付けてください。\n",
    "    \"\"\"\n",
    "\n",
    "    # 会話履歴の初期化\n",
    "    history = [\n",
    "        glm.Content(role='user', parts=[glm.Part(text=default_initial_prompt)]),\n",
    "        glm.Content(role='model', parts=[glm.Part(text='わかりました')])\n",
    "    ]\n",
    "\n",
    "    # Geminiチャットモデルの初期化\n",
    "    chat = genai.GenerativeModel('gemini-1.5-pro-latest').start_chat(history=history)\n",
    "    \n",
    "    return chat, history\n",
    "\n",
    "# メイン処理\n",
    "def main():\n",
    "    user_name = \"kawaii\"\n",
    "    \n",
    "    # まずはカメラから画像をキャプチャ\n",
    "    image_path = capture_image_from_camera()\n",
    "\n",
    "    if image_path:\n",
    "        # 画像ファイルをアップロードして分類\n",
    "        image = genai.upload_file(image_path)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "        result = model.generate_content(\n",
    "            [\"What kind of scenery is this:\", image],\n",
    "            generation_config=genai.GenerationConfig(\n",
    "                response_mime_type=\"text/x.enum\", \n",
    "                response_schema={\n",
    "                    \"type\": \"string\",  \n",
    "                    \"enum\": [\"Mountain\", \"Sea\", \"Landscape\"]\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "        scenery_type = result.text  # 結果を変数に保存\n",
    "        print(f\"画像は {scenery_type} に分類されました。\")\n",
    "        \n",
    "        # 分類結果に基づいてチャットを開始\n",
    "        chat, history = create_chat(user_name, scenery_type)\n",
    "\n",
    "        # チャット部分の処理\n",
    "        while True:\n",
    "            prompt = input('なにか話してください：　')\n",
    "            if prompt == 'exit':\n",
    "                break\n",
    "\n",
    "            response = chat.send_message(prompt)\n",
    "\n",
    "            # 履歴に新しいユーザーメッセージと応答を追加する\n",
    "            history.append(glm.Content(role='user', parts=[glm.Part(text=prompt)]))\n",
    "            history.append(glm.Content(role='model', parts=[glm.Part(text=response.text)]))\n",
    "\n",
    "            print(f'{user_name}: {prompt}')\n",
    "            print(f'BOT: {response.text}\\n')\n",
    "        \n",
    "        print(history)\n",
    "        for message in chat.history:\n",
    "            print(f\"{message.role}: {message.parts[0].text}\")\n",
    "    else:\n",
    "        print(\"画像がキャプチャできませんでした。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
